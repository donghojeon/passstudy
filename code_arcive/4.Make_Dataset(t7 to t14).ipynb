{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 학습을 위한 데이터 구분 및 디렉토리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pyjarowinkler import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'LearningData'\n",
    "\n",
    "# Columns\n",
    "c = ['N/A','low', 'num','low&num','up', 'up&low','up&num', 'up&num&low',\n",
    "     'spc', 'spc&low', 'spc&num', 'spc&num&low','spc&up', 'spc&up&low', 'spc&up&num', 'all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LN   3\n",
    "LN LNU + LNS 3  -> 7,11\n",
    "LU NLU + LUS 5  -> 7,13\n",
    "LS LNS + LUS  9  -> 11,13\n",
    "NU LNU         6  -> 7\n",
    "LNU LNU        7\n",
    "LNS LNS        11\n",
    "LNU+LNS+LUS+LUN ALL 7,11,13,14 -> 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_7  = [c[3]]           \n",
    "type_8  = [c[3],[c[7],c[11]]]  \n",
    "type_9  = [c[5],[c[7],c[13]]]   \n",
    "type_10 = [c[9],[c[11],c[13]]]   \n",
    "type_11 = [c[6],c[7]]           \n",
    "type_12 = [c[7]]   \n",
    "type_13 = [c[11]]   \n",
    "type_14 = [[c[7],c[11],c[13],c[14]], c[15]]\n",
    "\n",
    "extra_path = '/letter_specific_data'\n",
    "type_7_path = os.path.join(base_path, 'type_7'+extra_path)\n",
    "type_8_path = os.path.join(base_path, 'type_8'+extra_path)\n",
    "type_9_path = os.path.join(base_path, 'type_9'+extra_path)\n",
    "type_10_path = os.path.join(base_path, 'type_10'+extra_path)\n",
    "type_11_path = os.path.join(base_path, 'type_11'+extra_path)\n",
    "type_12_path = os.path.join(base_path, 'type_12'+extra_path)\n",
    "type_13_path = os.path.join(base_path, 'type_13'+extra_path)\n",
    "type_14_path = os.path.join(base_path, 'type_14'+extra_path)\n",
    "\n",
    "\n",
    "if not os.path.exists(type_7_path):os.makedirs(type_7_path)\n",
    "if not os.path.exists(type_8_path):os.makedirs(type_8_path)\n",
    "if not os.path.exists(type_9_path):os.makedirs(type_9_path)\n",
    "if not os.path.exists(type_10_path):os.makedirs(type_10_path)    \n",
    "if not os.path.exists(type_11_path):os.makedirs(type_11_path)\n",
    "if not os.path.exists(type_12_path):os.makedirs(type_12_path)    \n",
    "if not os.path.exists(type_13_path):os.makedirs(type_13_path)    \n",
    "if not os.path.exists(type_14_path):os.makedirs(type_14_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = list(string.ascii_lowercase) +['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     7,
     20,
     32
    ]
   },
   "outputs": [],
   "source": [
    "def delete_single(src):\n",
    "    \n",
    "    if src <2:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return src\n",
    "    \n",
    "def SplitData(listin):\n",
    "    \n",
    "    length = len(listin)\n",
    "    listout = list()\n",
    "    \n",
    "    tmp = random.sample(listin, length)\n",
    "        \n",
    "    for i in range(length-1):\n",
    "        tmp_list = [tmp[0], tmp[i+1]]\n",
    "        listout.append(tmp_list)\n",
    "    \n",
    "    return listout\n",
    "\n",
    "def DropReindex(learn_data, TYPE):\n",
    "    \n",
    "    learn_data = learn_data.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data['length'] = learn_data[TYPE[0]].str.len()\n",
    "    learn_data['length'] = learn_data['length'].apply(delete_single)\n",
    "\n",
    "    learn_data = learn_data.dropna(how='any')\n",
    "    learn_data = learn_data.drop('length', axis = 1)\n",
    "    learn_data = learn_data.reset_index(drop=True)\n",
    "\n",
    "    return learn_data\n",
    "\n",
    "def ListExtend(listin):\n",
    "    \n",
    "    tmp = list()\n",
    "    \n",
    "    for i in range(len(listin)):\n",
    "        out = listin['Splitted'][i]\n",
    "        tmp.extend(out)\n",
    "        \n",
    "        if i%100000==0:\n",
    "            print(i)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def DFandSave(learn_data, TYPE ,char):\n",
    "    \n",
    "    base = './LearningData/type_'+ str(TYPE)+ '/letter_specific_data/'\n",
    "    save_path = base+str(char)+'.pickle'\n",
    "    \n",
    "    data_columns = ['src', 'tgt']\n",
    "    pw_data = pd.DataFrame(learn_data, columns=data_columns)\n",
    "    pw_data.to_pickle(save_path)\n",
    "    \n",
    "    print(char, 'Data Saved', 'length=',len(pw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def SplitData_Multi(data_src, data_tgt):\n",
    "    \n",
    "    listout = list()\n",
    "    \n",
    "    for i in range(len(data_src)):\n",
    "        src = data_src[i]\n",
    "        \n",
    "        for j in range(len(data_tgt)):\n",
    "            tgt = data_tgt[j]\n",
    "            tmp = [src,tgt]\n",
    "            listout.append(tmp)\n",
    "    \n",
    "    return listout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 Split&Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 3418768\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "a Data Saved length= 6613331\n",
      "\n",
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 2022125\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "b Data Saved length= 3651580\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 1851783\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "c Data Saved length= 3302388\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 2267495\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "d Data Saved length= 4334826\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 1022258\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "e Data Saved length= 1981045\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 988753\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "f Data Saved length= 2003986\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 1248812\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "g Data Saved length= 2432635\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 923361\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "h Data Saved length= 1621532\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 828173\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "i Data Saved length= 1654855\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 1867194\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "j Data Saved length= 3039752\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 2017603\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "k Data Saved length= 3876219\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 1847274\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "l Data Saved length= 3439713\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 3199748\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "m Data Saved length= 6052011\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 1387630\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "n Data Saved length= 2699520\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 544411\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "o Data Saved length= 1097272\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 1387697\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "p Data Saved length= 2619506\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 164332\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "q Data Saved length= 326677\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 1547842\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "r Data Saved length= 2842056\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 3438505\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "s Data Saved length= 6462308\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 1577011\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "t Data Saved length= 2842565\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 226447\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "u Data Saved length= 525665\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 1025808\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "v Data Saved length= 2159189\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 720854\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "w Data Saved length= 1245346\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 265962\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "x Data Saved length= 444088\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 441682\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "y Data Saved length= 829965\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 470221\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "z Data Saved length= 935477\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 1268854\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "num Data Saved length= 12589163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data = pw_df[type_7]\n",
    "    print('length of original learn data:',len(learn_data))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data = DropReindex(learn_data, type_7)\n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data['low&num'].apply(SplitData)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,7,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900d1d344</td>\n",
       "      <td>900d1d34900d1d34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900d1d344</td>\n",
       "      <td>900d1d34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900d1d344</td>\n",
       "      <td>9900d1d34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900d1d344</td>\n",
       "      <td>900d1d341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ber090909</td>\n",
       "      <td>ber0909099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651575</th>\n",
       "      <td>may821aw</td>\n",
       "      <td>may821a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651576</th>\n",
       "      <td>may821aw</td>\n",
       "      <td>may821a123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651577</th>\n",
       "      <td>may821aw</td>\n",
       "      <td>may821a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651578</th>\n",
       "      <td>may821aw</td>\n",
       "      <td>may821aqwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651579</th>\n",
       "      <td>man420</td>\n",
       "      <td>max420djan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3651580 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               src               tgt\n",
       "0        900d1d344  900d1d34900d1d34\n",
       "1        900d1d344          900d1d34\n",
       "2        900d1d344         9900d1d34\n",
       "3        900d1d344         900d1d341\n",
       "4        ber090909        ber0909099\n",
       "...            ...               ...\n",
       "3651575   may821aw           may821a\n",
       "3651576   may821aw        may821a123\n",
       "3651577   may821aw           may821a\n",
       "3651578   may821aw        may821aqwe\n",
       "3651579     man420        max420djan\n",
       "\n",
       "[3651580 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 올바른 전처리 결과 확인용\n",
    "pd.read_pickle('./LearningData/type_7/letter_specific_data/b.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data load and Append\n",
      "6613331\n",
      "b Data load and Append\n",
      "3651580\n",
      "c Data load and Append\n",
      "3302388\n",
      "d Data load and Append\n",
      "4334826\n",
      "e Data load and Append\n",
      "1981045\n",
      "f Data load and Append\n",
      "2003986\n",
      "g Data load and Append\n",
      "2432635\n",
      "h Data load and Append\n",
      "1621532\n",
      "i Data load and Append\n",
      "1654855\n",
      "j Data load and Append\n",
      "3039752\n",
      "k Data load and Append\n",
      "3876219\n",
      "l Data load and Append\n",
      "3439713\n",
      "m Data load and Append\n",
      "6052011\n",
      "n Data load and Append\n",
      "2699520\n",
      "o Data load and Append\n",
      "1097272\n",
      "p Data load and Append\n",
      "2619506\n",
      "q Data load and Append\n",
      "326677\n",
      "r Data load and Append\n",
      "2842056\n",
      "s Data load and Append\n",
      "6462308\n",
      "t Data load and Append\n",
      "2842565\n",
      "u Data load and Append\n",
      "525665\n",
      "v Data load and Append\n",
      "2159189\n",
      "w Data load and Append\n",
      "1245346\n",
      "x Data load and Append\n",
      "444088\n",
      "y Data load and Append\n",
      "829965\n",
      "z Data load and Append\n",
      "935477\n",
      "num Data load and Append\n",
      "12589163\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 데이터 a~z, num 들을 로드한 후 1개의 df로 결합\n",
    "\n",
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data load and Append')\n",
    "    \n",
    "    load_path = './LearningData/type_7/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81622670"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low&num'] 갯수 : 81622670\n",
      "\n",
      "                src          tgt\n",
      "0  aidos12345678901  ai123456789\n",
      "1  aidos12345678901   a123456789\n",
      "2           nikola1     nikola91\n",
      "3           nikola1     nikola19\n",
      "4           nikola1     nikola99\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 7\n",
    "save_path = type_7_path[:-20]\n",
    "print('%s 갯수 : %d\\n' % (type_7, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 모두 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('./LearningData/type_1/pw_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 768615\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "b Data Saved length= 2698210\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 698341\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "c Data Saved length= 2428094\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 929111\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "d Data Saved length= 3284164\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 436320\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "e Data Saved length= 1569957\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 386658\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "f Data Saved length= 1499877\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 508816\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "g Data Saved length= 1822808\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 342483\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "h Data Saved length= 1139639\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 332099\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "i Data Saved length= 1223422\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 715006\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "j Data Saved length= 1984190\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 814534\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "k Data Saved length= 2830845\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 692179\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "l Data Saved length= 2440215\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 1267302\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "m Data Saved length= 4277695\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 557607\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "n Data Saved length= 1930156\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 245244\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "o Data Saved length= 863423\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 556793\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "p Data Saved length= 1966998\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 51330\n",
      "Data Splitted\n",
      "0\n",
      "q Data Saved length= 169440\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 635670\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "r Data Saved length= 2036583\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 1334553\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "s Data Saved length= 4538194\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 599695\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "t Data Saved length= 1889089\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 86447\n",
      "Data Splitted\n",
      "0\n",
      "u Data Saved length= 310819\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 425639\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "v Data Saved length= 1678430\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 232253\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "w Data Saved length= 733620\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 90173\n",
      "Data Splitted\n",
      "0\n",
      "x Data Saved length= 276670\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 157491\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "y Data Saved length= 560518\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 188752\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "z Data Saved length= 706637\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 254325\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "num Data Saved length= 979430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data1 = pw_df[[type_8[0], type_8[1][0]]]\n",
    "    learn_data2 = pw_df[[type_8[0], type_8[1][1]]]\n",
    "    print('length of original learn data:',len(learn_data1))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data1 = learn_data1.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data2 = learn_data2.dropna(how='any').reset_index(drop=True)\n",
    "    \n",
    "    learn_data2.rename(columns = {'spc&num&low':'up&num&low'}, inplace=True)\n",
    "    learn_data = learn_data1.append(learn_data2)\n",
    "    learn_data = learn_data.reset_index(drop=True)\n",
    "    \n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data.apply(lambda x:SplitData_Multi(x[type_8[0]], x[type_8[1][0]]), axis = 1)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,8,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sbt123</td>\n",
       "      <td>SBTsbt123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alex12044</td>\n",
       "      <td>Alex1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aalex1204</td>\n",
       "      <td>Alex1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alex12041</td>\n",
       "      <td>Alex1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alex1204</td>\n",
       "      <td>Alex1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284159</th>\n",
       "      <td>toyotasupra3</td>\n",
       "      <td>toyota3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284160</th>\n",
       "      <td>qwerty1310</td>\n",
       "      <td>qwerty34.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284161</th>\n",
       "      <td>qwerty12345</td>\n",
       "      <td>qwerty34.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284162</th>\n",
       "      <td>ul3gomaja</td>\n",
       "      <td>ul.3-go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284163</th>\n",
       "      <td>dg97grus02</td>\n",
       "      <td>dg97grus02.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3284164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  src          tgt\n",
       "0              sbt123    SBTsbt123\n",
       "1           alex12044     Alex1204\n",
       "2           aalex1204     Alex1204\n",
       "3           alex12041     Alex1204\n",
       "4            alex1204     Alex1204\n",
       "...               ...          ...\n",
       "3284159  toyotasupra3    toyota3.0\n",
       "3284160    qwerty1310    qwerty34.\n",
       "3284161   qwerty12345    qwerty34.\n",
       "3284162     ul3gomaja      ul.3-go\n",
       "3284163    dg97grus02  dg97grus02.\n",
       "\n",
       "[3284164 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_8/letter_specific_data/d.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "4901173\n",
      "b Data\n",
      "2698210\n",
      "c Data\n",
      "2428094\n",
      "d Data\n",
      "3284164\n",
      "e Data\n",
      "1569957\n",
      "f Data\n",
      "1499877\n",
      "g Data\n",
      "1822808\n",
      "h Data\n",
      "1139639\n",
      "i Data\n",
      "1223422\n",
      "j Data\n",
      "1984190\n",
      "k Data\n",
      "2830845\n",
      "l Data\n",
      "2440215\n",
      "m Data\n",
      "4277695\n",
      "n Data\n",
      "1930156\n",
      "o Data\n",
      "863423\n",
      "p Data\n",
      "1966998\n",
      "q Data\n",
      "169440\n",
      "r Data\n",
      "2036583\n",
      "s Data\n",
      "4538194\n",
      "t Data\n",
      "1889089\n",
      "u Data\n",
      "310819\n",
      "v Data\n",
      "1678430\n",
      "w Data\n",
      "733620\n",
      "x Data\n",
      "276670\n",
      "y Data\n",
      "560518\n",
      "z Data\n",
      "706637\n",
      "num Data\n",
      "979430\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_8/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50740296"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low&num', ['up&num&low', 'spc&num&low']] 갯수 : 50740296\n",
      "\n",
      "              src           tgt\n",
      "0       aidar1969  aiDAR7aidar5\n",
      "1       aidar8690  aiDAR7aidar5\n",
      "2       aidar1969  aiDAR7aidar5\n",
      "3  baldo72baldo72       Baldo72\n",
      "4         baldo72       Baldo72\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 8\n",
    "save_path = type_8_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_8, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 154090\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "a Data Saved length= 543164\n",
      "\n",
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 85637\n",
      "Data Splitted\n",
      "0\n",
      "b Data Saved length= 341429\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 70369\n",
      "Data Splitted\n",
      "0\n",
      "c Data Saved length= 266571\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 107066\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "d Data Saved length= 413348\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 49328\n",
      "Data Splitted\n",
      "0\n",
      "e Data Saved length= 202941\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 42648\n",
      "Data Splitted\n",
      "0\n",
      "f Data Saved length= 179276\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 57043\n",
      "Data Splitted\n",
      "0\n",
      "g Data Saved length= 212303\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 37483\n",
      "Data Splitted\n",
      "0\n",
      "h Data Saved length= 163565\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 41712\n",
      "Data Splitted\n",
      "0\n",
      "i Data Saved length= 164827\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 64545\n",
      "Data Splitted\n",
      "0\n",
      "j Data Saved length= 233312\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 84276\n",
      "Data Splitted\n",
      "0\n",
      "k Data Saved length= 312604\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 66491\n",
      "Data Splitted\n",
      "0\n",
      "l Data Saved length= 255873\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 130807\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "m Data Saved length= 531017\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 58171\n",
      "Data Splitted\n",
      "0\n",
      "n Data Saved length= 208440\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 27328\n",
      "Data Splitted\n",
      "0\n",
      "o Data Saved length= 106113\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 62978\n",
      "Data Splitted\n",
      "0\n",
      "p Data Saved length= 248546\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 4572\n",
      "Data Splitted\n",
      "0\n",
      "q Data Saved length= 15865\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 68615\n",
      "Data Splitted\n",
      "0\n",
      "r Data Saved length= 263725\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 140033\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "s Data Saved length= 538012\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 63723\n",
      "Data Splitted\n",
      "0\n",
      "t Data Saved length= 262359\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 11485\n",
      "Data Splitted\n",
      "0\n",
      "u Data Saved length= 49964\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 51156\n",
      "Data Splitted\n",
      "0\n",
      "v Data Saved length= 201794\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 23320\n",
      "Data Splitted\n",
      "0\n",
      "w Data Saved length= 98563\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 8670\n",
      "Data Splitted\n",
      "0\n",
      "x Data Saved length= 31607\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 16002\n",
      "Data Splitted\n",
      "0\n",
      "y Data Saved length= 61762\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 22280\n",
      "Data Splitted\n",
      "0\n",
      "z Data Saved length= 85601\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 21129\n",
      "Data Splitted\n",
      "0\n",
      "num Data Saved length= 100383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data1 = pw_df[[type_9[0], type_9[1][0]]]\n",
    "    learn_data2 = pw_df[[type_9[0], type_9[1][1]]]\n",
    "    print('length of original learn data:',len(learn_data1))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data1 = learn_data1.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data2 = learn_data2.dropna(how='any').reset_index(drop=True)\n",
    "    \n",
    "    learn_data2.rename(columns = {'spc&up&low':'up&num&low'}, inplace=True)\n",
    "    learn_data = learn_data1.append(learn_data2)\n",
    "    learn_data = learn_data.reset_index(drop=True)\n",
    "    \n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data.apply(lambda x:SplitData_Multi(x[type_9[0]], x[type_9[1][0]]), axis = 1)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,9,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "543164\n",
      "b Data\n",
      "341429\n",
      "c Data\n",
      "266571\n",
      "d Data\n",
      "413348\n",
      "e Data\n",
      "202941\n",
      "f Data\n",
      "179276\n",
      "g Data\n",
      "212303\n",
      "h Data\n",
      "163565\n",
      "i Data\n",
      "164827\n",
      "j Data\n",
      "233312\n",
      "k Data\n",
      "312604\n",
      "l Data\n",
      "255873\n",
      "m Data\n",
      "531017\n",
      "n Data\n",
      "208440\n",
      "o Data\n",
      "106113\n",
      "p Data\n",
      "248546\n",
      "q Data\n",
      "15865\n",
      "r Data\n",
      "263725\n",
      "s Data\n",
      "538012\n",
      "t Data\n",
      "262359\n",
      "u Data\n",
      "49964\n",
      "v Data\n",
      "201794\n",
      "w Data\n",
      "98563\n",
      "x Data\n",
      "31607\n",
      "y Data\n",
      "61762\n",
      "z Data\n",
      "85601\n",
      "num Data\n",
      "100383\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_9/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aUGekWSY</td>\n",
       "      <td>aUGekWSY11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aUGekWSY</td>\n",
       "      <td>72aUGekWSY1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aUGekWSY</td>\n",
       "      <td>aUGekWSY1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aUGekWSY</td>\n",
       "      <td>aUGekWSY11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SlinnotnaSlinnotna</td>\n",
       "      <td>Slinnotna1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179271</th>\n",
       "      <td>Fxllyelen</td>\n",
       "      <td>Fxlly_condoR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179272</th>\n",
       "      <td>Fylhttd</td>\n",
       "      <td>Fylhttd-nkn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179273</th>\n",
       "      <td>FylhttD</td>\n",
       "      <td>Fylhttd-nkn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179274</th>\n",
       "      <td>Fyodaroff</td>\n",
       "      <td>Fyodaroff@mail.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179275</th>\n",
       "      <td>FyutkfHekzn</td>\n",
       "      <td>Fyutksyfuevty.r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       src                tgt\n",
       "0                 aUGekWSY         aUGekWSY11\n",
       "1                 aUGekWSY     72aUGekWSY1172\n",
       "2                 aUGekWSY       aUGekWSY1172\n",
       "3                 aUGekWSY         aUGekWSY11\n",
       "4       SlinnotnaSlinnotna         Slinnotna1\n",
       "...                    ...                ...\n",
       "179271           Fxllyelen       Fxlly_condoR\n",
       "179272             Fylhttd        Fylhttd-nkn\n",
       "179273             FylhttD        Fylhttd-nkn\n",
       "179274           Fyodaroff  Fyodaroff@mail.ru\n",
       "179275         FyutkfHekzn    Fyutksyfuevty.r\n",
       "\n",
       "[179276 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_9/letter_specific_data/f.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6092964"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up&low', ['up&num&low', 'spc&up&low']] 갯수 : 6092964\n",
      "\n",
      "          src           tgt\n",
      "0    Andemtal  Andemtal1123\n",
      "1      Andemt  Andemtal1123\n",
      "2     Andemta  Andemtal1123\n",
      "3  AndemtalQq  Andemtal1123\n",
      "4   Andemtala  Andemtal1123\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 9\n",
    "save_path = type_9_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_9, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 163355\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "a Data Saved length= 555046\n",
      "\n",
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 61068\n",
      "Data Splitted\n",
      "0\n",
      "b Data Saved length= 202684\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 51715\n",
      "Data Splitted\n",
      "0\n",
      "c Data Saved length= 180353\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 89013\n",
      "Data Splitted\n",
      "0\n",
      "d Data Saved length= 318253\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 45001\n",
      "Data Splitted\n",
      "0\n",
      "e Data Saved length= 153885\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 30806\n",
      "Data Splitted\n",
      "0\n",
      "f Data Saved length= 94926\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 44242\n",
      "Data Splitted\n",
      "0\n",
      "g Data Saved length= 141564\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 22822\n",
      "Data Splitted\n",
      "0\n",
      "h Data Saved length= 63984\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 35616\n",
      "Data Splitted\n",
      "0\n",
      "i Data Saved length= 110917\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 45138\n",
      "Data Splitted\n",
      "0\n",
      "j Data Saved length= 141272\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 73541\n",
      "Data Splitted\n",
      "0\n",
      "k Data Saved length= 233560\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 58262\n",
      "Data Splitted\n",
      "0\n",
      "l Data Saved length= 184938\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 114223\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "m Data Saved length= 349809\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 58624\n",
      "Data Splitted\n",
      "0\n",
      "n Data Saved length= 176852\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 28655\n",
      "Data Splitted\n",
      "0\n",
      "o Data Saved length= 84507\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 47018\n",
      "Data Splitted\n",
      "0\n",
      "p Data Saved length= 131896\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 3683\n",
      "Data Splitted\n",
      "0\n",
      "q Data Saved length= 11511\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 52657\n",
      "Data Splitted\n",
      "0\n",
      "r Data Saved length= 161795\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 142892\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "s Data Saved length= 437591\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 47776\n",
      "Data Splitted\n",
      "0\n",
      "t Data Saved length= 142972\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 8192\n",
      "Data Splitted\n",
      "0\n",
      "u Data Saved length= 26485\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 49913\n",
      "Data Splitted\n",
      "0\n",
      "v Data Saved length= 148770\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 15399\n",
      "Data Splitted\n",
      "0\n",
      "w Data Saved length= 49480\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 4997\n",
      "Data Splitted\n",
      "0\n",
      "x Data Saved length= 13791\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 18027\n",
      "Data Splitted\n",
      "0\n",
      "y Data Saved length= 49916\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 19705\n",
      "Data Splitted\n",
      "0\n",
      "z Data Saved length= 71133\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 27518\n",
      "Data Splitted\n",
      "0\n",
      "num Data Saved length= 115338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data1 = pw_df[[type_10[0], type_10[1][0]]]\n",
    "    learn_data2 = pw_df[[type_10[0], type_10[1][1]]]\n",
    "    print('length of original learn data:',len(learn_data1))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data1 = learn_data1.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data2 = learn_data2.dropna(how='any').reset_index(drop=True)\n",
    "    \n",
    "    learn_data2.rename(columns = {'spc&up&low':'spc&num&low'}, inplace=True)\n",
    "    learn_data = learn_data1.append(learn_data2)\n",
    "    learn_data = learn_data.reset_index(drop=True)\n",
    "    \n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data.apply(lambda x:SplitData_Multi(x[type_10[0]], x[type_10[1][0]]), axis = 1)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,10,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kimbum!</td>\n",
       "      <td>kimbum99!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kimbum!</td>\n",
       "      <td>kimbum99!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimbum!</td>\n",
       "      <td>kimbum99!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kimbum!</td>\n",
       "      <td>kimbum99!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kimbum!</td>\n",
       "      <td>kimbum99!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233555</th>\n",
       "      <td>kyushu.kudrya</td>\n",
       "      <td>Kyushu.kudrya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233556</th>\n",
       "      <td>kyushu.kudrya</td>\n",
       "      <td>Kyushu.kudrya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233557</th>\n",
       "      <td>kyushu.kudrya</td>\n",
       "      <td>Kyushu.kudrya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233558</th>\n",
       "      <td>kyuuzaki_l</td>\n",
       "      <td>Kyuuzaki_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233559</th>\n",
       "      <td>kyuuzaki_l</td>\n",
       "      <td>Kyuuzaki_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  src            tgt\n",
       "0             kimbum!      kimbum99!\n",
       "1             kimbum!      kimbum99!\n",
       "2             kimbum!      kimbum99!\n",
       "3             kimbum!      kimbum99!\n",
       "4             kimbum!      kimbum99!\n",
       "...               ...            ...\n",
       "233555  kyushu.kudrya  Kyushu.kudrya\n",
       "233556  kyushu.kudrya  Kyushu.kudrya\n",
       "233557  kyushu.kudrya  Kyushu.kudrya\n",
       "233558     kyuuzaki_l     Kyuuzaki_L\n",
       "233559     kyuuzaki_l      Kyuuzaki_\n",
       "\n",
       "[233560 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_10/letter_specific_data/k.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "555046\n",
      "b Data\n",
      "202684\n",
      "c Data\n",
      "180353\n",
      "d Data\n",
      "318253\n",
      "e Data\n",
      "153885\n",
      "f Data\n",
      "94926\n",
      "g Data\n",
      "141564\n",
      "h Data\n",
      "63984\n",
      "i Data\n",
      "110917\n",
      "j Data\n",
      "141272\n",
      "k Data\n",
      "233560\n",
      "l Data\n",
      "184938\n",
      "m Data\n",
      "349809\n",
      "n Data\n",
      "176852\n",
      "o Data\n",
      "84507\n",
      "p Data\n",
      "131896\n",
      "q Data\n",
      "11511\n",
      "r Data\n",
      "161795\n",
      "s Data\n",
      "437591\n",
      "t Data\n",
      "142972\n",
      "u Data\n",
      "26485\n",
      "v Data\n",
      "148770\n",
      "w Data\n",
      "49480\n",
      "x Data\n",
      "13791\n",
      "y Data\n",
      "49916\n",
      "z Data\n",
      "71133\n",
      "num Data\n",
      "115338\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_10/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4353228"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spc&low', ['spc&num&low', 'spc&up&low']] 갯수 : 4353228\n",
      "\n",
      "          src            tgt\n",
      "0     a-----a       a-----a1\n",
      "1     a-----a       a-----05\n",
      "2     a----ha       a-----05\n",
      "3      a----k       a-----05\n",
      "4  no_pasaran  no_pasaran123\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 10\n",
    "save_path = type_10_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_10, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 234925\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "a Data Saved length= 2623709\n",
      "\n",
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 117951\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "b Data Saved length= 561503\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 100930\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "c Data Saved length= 314133\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 135143\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "d Data Saved length= 623665\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 66287\n",
      "Data Splitted\n",
      "0\n",
      "e Data Saved length= 235427\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 65609\n",
      "Data Splitted\n",
      "0\n",
      "f Data Saved length= 335233\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 84131\n",
      "Data Splitted\n",
      "0\n",
      "g Data Saved length= 692969\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 44151\n",
      "Data Splitted\n",
      "0\n",
      "h Data Saved length= 218496\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 58651\n",
      "Data Splitted\n",
      "0\n",
      "i Data Saved length= 297692\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 77839\n",
      "Data Splitted\n",
      "0\n",
      "j Data Saved length= 702884\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 120768\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "k Data Saved length= 833286\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 99967\n",
      "Data Splitted\n",
      "0\n",
      "l Data Saved length= 447788\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 178281\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "m Data Saved length= 1520412\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 88389\n",
      "Data Splitted\n",
      "0\n",
      "n Data Saved length= 902511\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 47275\n",
      "Data Splitted\n",
      "0\n",
      "o Data Saved length= 406136\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 83485\n",
      "Data Splitted\n",
      "0\n",
      "p Data Saved length= 404185\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 5821\n",
      "Data Splitted\n",
      "0\n",
      "q Data Saved length= 17777\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 84120\n",
      "Data Splitted\n",
      "0\n",
      "r Data Saved length= 570866\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 187350\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "s Data Saved length= 1254802\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 79622\n",
      "Data Splitted\n",
      "0\n",
      "t Data Saved length= 541025\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 14145\n",
      "Data Splitted\n",
      "0\n",
      "u Data Saved length= 52634\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 75753\n",
      "Data Splitted\n",
      "0\n",
      "v Data Saved length= 396161\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 30742\n",
      "Data Splitted\n",
      "0\n",
      "w Data Saved length= 272198\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 13760\n",
      "Data Splitted\n",
      "0\n",
      "x Data Saved length= 147999\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 24158\n",
      "Data Splitted\n",
      "0\n",
      "y Data Saved length= 103959\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 32187\n",
      "Data Splitted\n",
      "0\n",
      "z Data Saved length= 230417\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 39129\n",
      "Data Splitted\n",
      "0\n",
      "num Data Saved length= 128672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data = pw_df[type_11]\n",
    "    print('length of original learn data:',len(learn_data))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data = learn_data.dropna(how='any').reset_index(drop=True)\n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data.apply(lambda x:SplitData_Multi(x[type_11[0]], x[type_11[1]]), axis = 1)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,11,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PKG306166</td>\n",
       "      <td>Pkg30616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PPKG30616</td>\n",
       "      <td>Pkg30616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PKG30616PKG30616</td>\n",
       "      <td>Pkg30616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PKG306161</td>\n",
       "      <td>Pkg30616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PKG30616</td>\n",
       "      <td>Pkg30616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692964</th>\n",
       "      <td>850340728G</td>\n",
       "      <td>850340728Ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692965</th>\n",
       "      <td>850340728G</td>\n",
       "      <td>850340728Gw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692966</th>\n",
       "      <td>89503407298G123</td>\n",
       "      <td>850340728Ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692967</th>\n",
       "      <td>89503407298G123</td>\n",
       "      <td>850340728Gw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692968</th>\n",
       "      <td>QWE12QWE</td>\n",
       "      <td>Qwe12qwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692969 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     src          tgt\n",
       "0              PKG306166     Pkg30616\n",
       "1              PPKG30616     Pkg30616\n",
       "2       PKG30616PKG30616     Pkg30616\n",
       "3              PKG306161     Pkg30616\n",
       "4               PKG30616     Pkg30616\n",
       "...                  ...          ...\n",
       "692964        850340728G  850340728Ga\n",
       "692965        850340728G  850340728Gw\n",
       "692966   89503407298G123  850340728Ga\n",
       "692967   89503407298G123  850340728Gw\n",
       "692968          QWE12QWE     Qwe12qwe\n",
       "\n",
       "[692969 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_11/letter_specific_data/g.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "2623709\n",
      "b Data\n",
      "561503\n",
      "c Data\n",
      "314133\n",
      "d Data\n",
      "623665\n",
      "e Data\n",
      "235427\n",
      "f Data\n",
      "335233\n",
      "g Data\n",
      "692969\n",
      "h Data\n",
      "218496\n",
      "i Data\n",
      "297692\n",
      "j Data\n",
      "702884\n",
      "k Data\n",
      "833286\n",
      "l Data\n",
      "447788\n",
      "m Data\n",
      "1520412\n",
      "n Data\n",
      "902511\n",
      "o Data\n",
      "406136\n",
      "p Data\n",
      "404185\n",
      "q Data\n",
      "17777\n",
      "r Data\n",
      "570866\n",
      "s Data\n",
      "1254802\n",
      "t Data\n",
      "541025\n",
      "u Data\n",
      "52634\n",
      "v Data\n",
      "396161\n",
      "w Data\n",
      "272198\n",
      "x Data\n",
      "147999\n",
      "y Data\n",
      "103959\n",
      "z Data\n",
      "230417\n",
      "num Data\n",
      "128672\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_11/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14836539"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up&num', 'up&num&low'] 갯수 : 14836539\n",
      "\n",
      "           src         tgt\n",
      "0  RRAMPS12345  Ramps12345\n",
      "1   RAMPS12345  Ramps12345\n",
      "2  RAMPS123451  Ramps12345\n",
      "3  RAMPS123455  Ramps12345\n",
      "4     CENTER2K    Center2k\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 11\n",
    "save_path = type_11_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_11, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 359667\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "a Data Saved length= 1045507\n",
      "\n",
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 183544\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "b Data Saved length= 408586\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 156535\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "c Data Saved length= 327019\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 223935\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "d Data Saved length= 496610\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 105655\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "e Data Saved length= 240907\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 99680\n",
      "Data Splitted\n",
      "0\n",
      "f Data Saved length= 229862\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 127780\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "g Data Saved length= 355568\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 78790\n",
      "Data Splitted\n",
      "0\n",
      "h Data Saved length= 181306\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 86335\n",
      "Data Splitted\n",
      "0\n",
      "i Data Saved length= 202332\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 156740\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "j Data Saved length= 395426\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 176155\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "k Data Saved length= 438154\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 147513\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "l Data Saved length= 333881\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 279560\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "m Data Saved length= 749031\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 129318\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "n Data Saved length= 366049\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 61857\n",
      "Data Splitted\n",
      "0\n",
      "o Data Saved length= 178881\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 127000\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "p Data Saved length= 295519\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 10340\n",
      "Data Splitted\n",
      "0\n",
      "q Data Saved length= 22830\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 144533\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "r Data Saved length= 358599\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 285992\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "200000\n",
      "s Data Saved length= 714798\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 138094\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "t Data Saved length= 363164\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 23667\n",
      "Data Splitted\n",
      "0\n",
      "u Data Saved length= 53540\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 98779\n",
      "Data Splitted\n",
      "0\n",
      "v Data Saved length= 244609\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 52612\n",
      "Data Splitted\n",
      "0\n",
      "w Data Saved length= 141974\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 23245\n",
      "Data Splitted\n",
      "0\n",
      "x Data Saved length= 71095\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 32795\n",
      "Data Splitted\n",
      "0\n",
      "y Data Saved length= 75453\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 44282\n",
      "Data Splitted\n",
      "0\n",
      "z Data Saved length= 116899\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 57787\n",
      "Data Splitted\n",
      "0\n",
      "num Data Saved length= 141490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data = pw_df[type_12]\n",
    "    print('length of original learn data:',len(learn_data))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data = DropReindex(learn_data, type_12)\n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data['up&num&low'].apply(SplitData)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,12,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarah19861</td>\n",
       "      <td>Sarah1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah19861</td>\n",
       "      <td>Sarah1986Sarah1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sarah19861</td>\n",
       "      <td>Sarah19866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah19861</td>\n",
       "      <td>SSarah1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vernonsmommie11</td>\n",
       "      <td>Vernonsmommie1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333876</th>\n",
       "      <td>zZ456852qQ778</td>\n",
       "      <td>zZ456852qQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333877</th>\n",
       "      <td>zZ456852qQ778</td>\n",
       "      <td>zZ456852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333878</th>\n",
       "      <td>zZqQ456852</td>\n",
       "      <td>zZ456852qQ778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333879</th>\n",
       "      <td>zZqQ456852</td>\n",
       "      <td>zZ456852qQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333880</th>\n",
       "      <td>LzyNieto1231</td>\n",
       "      <td>LzyNieto123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333881 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    src                 tgt\n",
       "0            Sarah19861           Sarah1986\n",
       "1            Sarah19861  Sarah1986Sarah1986\n",
       "2            Sarah19861          Sarah19866\n",
       "3            Sarah19861          SSarah1986\n",
       "4       Vernonsmommie11      Vernonsmommie1\n",
       "...                 ...                 ...\n",
       "333876    zZ456852qQ778          zZ456852qQ\n",
       "333877    zZ456852qQ778            zZ456852\n",
       "333878       zZqQ456852       zZ456852qQ778\n",
       "333879       zZqQ456852          zZ456852qQ\n",
       "333880     LzyNieto1231         LzyNieto123\n",
       "\n",
       "[333881 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_12/letter_specific_data/l.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "1045507\n",
      "b Data\n",
      "408586\n",
      "c Data\n",
      "327019\n",
      "d Data\n",
      "496610\n",
      "e Data\n",
      "240907\n",
      "f Data\n",
      "229862\n",
      "g Data\n",
      "355568\n",
      "h Data\n",
      "181306\n",
      "i Data\n",
      "202332\n",
      "j Data\n",
      "395426\n",
      "k Data\n",
      "438154\n",
      "l Data\n",
      "333881\n",
      "m Data\n",
      "749031\n",
      "n Data\n",
      "366049\n",
      "o Data\n",
      "178881\n",
      "p Data\n",
      "295519\n",
      "q Data\n",
      "22830\n",
      "r Data\n",
      "358599\n",
      "s Data\n",
      "714798\n",
      "t Data\n",
      "363164\n",
      "u Data\n",
      "53540\n",
      "v Data\n",
      "244609\n",
      "w Data\n",
      "141974\n",
      "x Data\n",
      "71095\n",
      "y Data\n",
      "75453\n",
      "z Data\n",
      "116899\n",
      "num Data\n",
      "141490\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_12/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8549089"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up&num&low'] 갯수 : 8549089\n",
      "\n",
      "         src      tgt\n",
      "0     29Kfyf  29Kfyf1\n",
      "1     29Kfyf  29Kfyfq\n",
      "2  Y4nPK4qwe   Y4nPK4\n",
      "3  Y4nPK4qwe  Y4nPK41\n",
      "4  Y4nPK4qwe  Y4nPK4q\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 12\n",
    "save_path = type_12_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_12, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 184801\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "a Data Saved length= 412115\n",
      "\n",
      "b Data Begin\n",
      "length of original learn data: 4914853\n",
      "length of processed learn data: 76768\n",
      "Data Splitted\n",
      "0\n",
      "b Data Saved length= 165433\n",
      "\n",
      "c Data Begin\n",
      "length of original learn data: 4661423\n",
      "length of processed learn data: 53528\n",
      "Data Splitted\n",
      "0\n",
      "c Data Saved length= 113659\n",
      "\n",
      "d Data Begin\n",
      "length of original learn data: 5593731\n",
      "length of processed learn data: 89693\n",
      "Data Splitted\n",
      "0\n",
      "d Data Saved length= 183925\n",
      "\n",
      "e Data Begin\n",
      "length of original learn data: 2715231\n",
      "length of processed learn data: 48397\n",
      "Data Splitted\n",
      "0\n",
      "e Data Saved length= 100106\n",
      "\n",
      "f Data Begin\n",
      "length of original learn data: 2582223\n",
      "length of processed learn data: 34232\n",
      "Data Splitted\n",
      "0\n",
      "f Data Saved length= 68703\n",
      "\n",
      "g Data Begin\n",
      "length of original learn data: 3284478\n",
      "length of processed learn data: 52790\n",
      "Data Splitted\n",
      "0\n",
      "g Data Saved length= 111690\n",
      "\n",
      "h Data Begin\n",
      "length of original learn data: 2382683\n",
      "length of processed learn data: 26253\n",
      "Data Splitted\n",
      "0\n",
      "h Data Saved length= 65759\n",
      "\n",
      "i Data Begin\n",
      "length of original learn data: 2093863\n",
      "length of processed learn data: 42178\n",
      "Data Splitted\n",
      "0\n",
      "i Data Saved length= 89150\n",
      "\n",
      "j Data Begin\n",
      "length of original learn data: 4720419\n",
      "length of processed learn data: 53149\n",
      "Data Splitted\n",
      "0\n",
      "j Data Saved length= 107699\n",
      "\n",
      "k Data Begin\n",
      "length of original learn data: 4982040\n",
      "length of processed learn data: 93765\n",
      "Data Splitted\n",
      "0\n",
      "k Data Saved length= 205732\n",
      "\n",
      "l Data Begin\n",
      "length of original learn data: 4680674\n",
      "length of processed learn data: 72322\n",
      "Data Splitted\n",
      "0\n",
      "l Data Saved length= 145439\n",
      "\n",
      "m Data Begin\n",
      "length of original learn data: 8157479\n",
      "length of processed learn data: 129767\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "m Data Saved length= 260052\n",
      "\n",
      "n Data Begin\n",
      "length of original learn data: 3498824\n",
      "length of processed learn data: 69742\n",
      "Data Splitted\n",
      "0\n",
      "n Data Saved length= 133095\n",
      "\n",
      "o Data Begin\n",
      "length of original learn data: 1508427\n",
      "length of processed learn data: 31819\n",
      "Data Splitted\n",
      "0\n",
      "o Data Saved length= 62954\n",
      "\n",
      "p Data Begin\n",
      "length of original learn data: 3667612\n",
      "length of processed learn data: 55658\n",
      "Data Splitted\n",
      "0\n",
      "p Data Saved length= 110796\n",
      "\n",
      "q Data Begin\n",
      "length of original learn data: 379237\n",
      "length of processed learn data: 6011\n",
      "Data Splitted\n",
      "0\n",
      "q Data Saved length= 13026\n",
      "\n",
      "r Data Begin\n",
      "length of original learn data: 4025951\n",
      "length of processed learn data: 60734\n",
      "Data Splitted\n",
      "0\n",
      "r Data Saved length= 120389\n",
      "\n",
      "s Data Begin\n",
      "length of original learn data: 8751026\n",
      "length of processed learn data: 162595\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "s Data Saved length= 308430\n",
      "\n",
      "t Data Begin\n",
      "length of original learn data: 4021928\n",
      "length of processed learn data: 58203\n",
      "Data Splitted\n",
      "0\n",
      "t Data Saved length= 115507\n",
      "\n",
      "u Data Begin\n",
      "length of original learn data: 578985\n",
      "length of processed learn data: 11022\n",
      "Data Splitted\n",
      "0\n",
      "u Data Saved length= 24432\n",
      "\n",
      "v Data Begin\n",
      "length of original learn data: 2579178\n",
      "length of processed learn data: 58478\n",
      "Data Splitted\n",
      "0\n",
      "v Data Saved length= 114912\n",
      "\n",
      "w Data Begin\n",
      "length of original learn data: 1800892\n",
      "length of processed learn data: 19774\n",
      "Data Splitted\n",
      "0\n",
      "w Data Saved length= 44264\n",
      "\n",
      "x Data Begin\n",
      "length of original learn data: 696787\n",
      "length of processed learn data: 6573\n",
      "Data Splitted\n",
      "0\n",
      "x Data Saved length= 13414\n",
      "\n",
      "y Data Begin\n",
      "length of original learn data: 1163990\n",
      "length of processed learn data: 20296\n",
      "Data Splitted\n",
      "0\n",
      "y Data Saved length= 41135\n",
      "\n",
      "z Data Begin\n",
      "length of original learn data: 1246548\n",
      "length of processed learn data: 26325\n",
      "Data Splitted\n",
      "0\n",
      "z Data Saved length= 58423\n",
      "\n",
      "num Data Begin\n",
      "length of original learn data: 2923676\n",
      "length of processed learn data: 31895\n",
      "Data Splitted\n",
      "0\n",
      "num Data Saved length= 82041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data = pw_df[type_13]\n",
    "    print('length of original learn data:',len(learn_data))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data = DropReindex(learn_data, type_13)\n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data['spc&num&low'].apply(SplitData)\n",
    "    print('Data Splitted')\n",
    "    \n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,13,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u-2-8181</td>\n",
       "      <td>u-2-8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albatros.13</td>\n",
       "      <td>albatross.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u-63qwe</td>\n",
       "      <td>u-63123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u-a-center123</td>\n",
       "      <td>u-a-center1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u-a-center123</td>\n",
       "      <td>u-a-center1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24427</th>\n",
       "      <td>aleksey.qwerty2012</td>\n",
       "      <td>aleksey.qwerty2012a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24428</th>\n",
       "      <td>butcher-77a</td>\n",
       "      <td>butcher-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24429</th>\n",
       "      <td>butcher-77a</td>\n",
       "      <td>butcher-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24430</th>\n",
       "      <td>uzhik81@mail.ru</td>\n",
       "      <td>uzhik87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24431</th>\n",
       "      <td>uzhik81@mail.ru</td>\n",
       "      <td>uzhik87%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      src                  tgt\n",
       "0                u-2-8181             u-2-8182\n",
       "1             albatros.13         albatross.13\n",
       "2                 u-63qwe              u-63123\n",
       "3           u-a-center123          u-a-center1\n",
       "4           u-a-center123          u-a-center1\n",
       "...                   ...                  ...\n",
       "24427  aleksey.qwerty2012  aleksey.qwerty2012a\n",
       "24428         butcher-77a           butcher-77\n",
       "24429         butcher-77a            butcher-7\n",
       "24430     uzhik81@mail.ru             uzhik87%\n",
       "24431     uzhik81@mail.ru             uzhik87%\n",
       "\n",
       "[24432 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_13/letter_specific_data/u.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "412115\n",
      "b Data\n",
      "165433\n",
      "c Data\n",
      "113659\n",
      "d Data\n",
      "183925\n",
      "e Data\n",
      "100106\n",
      "f Data\n",
      "68703\n",
      "g Data\n",
      "111690\n",
      "h Data\n",
      "65759\n",
      "i Data\n",
      "89150\n",
      "j Data\n",
      "107699\n",
      "k Data\n",
      "205732\n",
      "l Data\n",
      "145439\n",
      "m Data\n",
      "260052\n",
      "n Data\n",
      "133095\n",
      "o Data\n",
      "62954\n",
      "p Data\n",
      "110796\n",
      "q Data\n",
      "13026\n",
      "r Data\n",
      "120389\n",
      "s Data\n",
      "308430\n",
      "t Data\n",
      "115507\n",
      "u Data\n",
      "24432\n",
      "v Data\n",
      "114912\n",
      "w Data\n",
      "44264\n",
      "x Data\n",
      "13414\n",
      "y Data\n",
      "41135\n",
      "z Data\n",
      "58423\n",
      "num Data\n",
      "82041\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_13/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3272280"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spc&num&low'] 갯수 : 3272280\n",
      "\n",
      "                    src                   tgt\n",
      "0  chimp1984a@gmail.com  chimp1984a@yahoo.com\n",
      "1            a*bruck*31             a*bruck*3\n",
      "2              a-----a1              a-----05\n",
      "3              a----b19              a----b10\n",
      "4               a-00123               a-00qwe\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 13\n",
    "save_path = type_13_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_13, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LNU+LNS+LUS+LUN ALL 7,11,13,14 -> 15'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'LNU+LNS+LUS+LUN ALL 7,11,13,14 -> 15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data Begin\n",
      "length of original learn data: 8770116\n",
      "length of processed learn data: 139845\n",
      "Data Splitted\n",
      "0\n",
      "100000\n",
      "a Data Saved length= 473153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data Begin')\n",
    "    \n",
    "    # 데이터 로드\n",
    "    load_path = './Preprocessed/' +str(char)+'.pickle'\n",
    "    pw_df = pd.read_pickle(load_path)\n",
    "    \n",
    "    # 원하는 타입 추출\n",
    "    learn_data1 = pw_df[[type_14[0][0], type_14[1]]]\n",
    "    learn_data2 = pw_df[[type_14[0][1], type_14[1]]]\n",
    "    learn_data3 = pw_df[[type_14[0][2], type_14[1]]]\n",
    "    learn_data4 = pw_df[[type_14[0][3], type_14[1]]]\n",
    "    print('length of original learn data:',len(learn_data1))\n",
    "    \n",
    "    # 불필요한 데이터 drop 및 reindex\n",
    "    learn_data1 = learn_data1.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data2 = learn_data2.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data3 = learn_data3.dropna(how='any').reset_index(drop=True)\n",
    "    learn_data4 = learn_data4.dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "    learn_data2.rename(columns = {'spc&num&low':'up&num&low'}, inplace=True)\n",
    "    learn_data3.rename(columns = { 'spc&up&low':'up&num&low'}, inplace=True)\n",
    "    learn_data4.rename(columns = { 'spc&up&num':'up&num&low'}, inplace=True)\n",
    "\n",
    "    learn_data = learn_data1.append(learn_data2)\n",
    "    learn_data = learn_data.append(learn_data3)\n",
    "    learn_data = learn_data.append(learn_data4)\n",
    "\n",
    "    learn_data = learn_data.reset_index(drop=True)\n",
    "    print('length of processed learn data:',len(learn_data))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 길이가 2 이상인 데이터 나누기\n",
    "    learn_data['Splitted'] = learn_data.apply(lambda x:SplitData_Multi(x[type_14[0][0]], x[type_14[1]]), axis = 1)\n",
    "    print('Data Splitted')\n",
    "\n",
    "    # 나뉘어진 데이터 이어 붙이기 \n",
    "    learn_data= ListExtend(learn_data)\n",
    "    \n",
    "    # src, tgt 데이터 프래임 생성 및 파일 저장\n",
    "    DFandSave(learn_data,14,char)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duygia201555</td>\n",
       "      <td>Duygia20155!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duygia20155</td>\n",
       "      <td>Duygia20155!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DDuygia20155</td>\n",
       "      <td>Duygia20155!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duygia201551</td>\n",
       "      <td>Duygia20155!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Policeman1233</td>\n",
       "      <td>Policeman123!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109409</th>\n",
       "      <td>GWAPOME_00</td>\n",
       "      <td>Gwapome_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109410</th>\n",
       "      <td>GWAPOME_00</td>\n",
       "      <td>Gwapome_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109411</th>\n",
       "      <td>GWEN_BYERS126</td>\n",
       "      <td>Gwen_Byers126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109412</th>\n",
       "      <td>GWEN_BYERS126</td>\n",
       "      <td>Gwen_Byers12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109413</th>\n",
       "      <td>GWENN.SCHMIT6550</td>\n",
       "      <td>Gwenn.Schmit655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109414 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     src              tgt\n",
       "0           Duygia201555     Duygia20155!\n",
       "1            Duygia20155     Duygia20155!\n",
       "2           DDuygia20155     Duygia20155!\n",
       "3           Duygia201551     Duygia20155!\n",
       "4          Policeman1233    Policeman123!\n",
       "...                  ...              ...\n",
       "109409        GWAPOME_00        Gwapome_0\n",
       "109410        GWAPOME_00       Gwapome_00\n",
       "109411     GWEN_BYERS126    Gwen_Byers126\n",
       "109412     GWEN_BYERS126     Gwen_Byers12\n",
       "109413  GWENN.SCHMIT6550  Gwenn.Schmit655\n",
       "\n",
       "[109414 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('./LearningData/type_14/letter_specific_data/g.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Data\n",
      "473153\n",
      "b Data\n",
      "165018\n",
      "c Data\n",
      "141354\n",
      "d Data\n",
      "222051\n",
      "e Data\n",
      "108696\n",
      "f Data\n",
      "79432\n",
      "g Data\n",
      "109414\n",
      "h Data\n",
      "96603\n",
      "i Data\n",
      "62074\n",
      "j Data\n",
      "140487\n",
      "k Data\n",
      "187291\n",
      "l Data\n",
      "128510\n",
      "m Data\n",
      "282343\n",
      "n Data\n",
      "121785\n",
      "o Data\n",
      "48279\n",
      "p Data\n",
      "103615\n",
      "q Data\n",
      "8926\n",
      "r Data\n",
      "117470\n",
      "s Data\n",
      "251341\n",
      "t Data\n",
      "112545\n",
      "u Data\n",
      "20430\n",
      "v Data\n",
      "82343\n",
      "w Data\n",
      "50556\n",
      "x Data\n",
      "11885\n",
      "y Data\n",
      "28364\n",
      "z Data\n",
      "43684\n",
      "num Data\n",
      "73342\n"
     ]
    }
   ],
   "source": [
    "data_columns = ['src', 'tgt']\n",
    "pw_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "for i in range(0,27):\n",
    "    char = letter[i]\n",
    "    print(char, 'Data')\n",
    "    \n",
    "    load_path = './LearningData/type_14/letter_specific_data/'+str(char)+'.pickle'\n",
    "    temp = pd.read_pickle(load_path)\n",
    "    \n",
    "    print(len(temp))\n",
    "    pw_data = pw_data.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3270991"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['up&num&low', 'spc&num&low', 'spc&up&low', 'spc&up&num'], 'all'] 갯수 : 3270991\n",
      "\n",
      "            src            tgt\n",
      "0      4Funn1ng     4Funn1ng#1\n",
      "1  Dialog543123  Dialog543123$\n",
      "2   Rcirf090687      Rc.irf006\n",
      "3   Rcirf090687     Rc.irf0068\n",
      "4   Rcirf090687    Rc.irf00687\n",
      "src -> tgt\n"
     ]
    }
   ],
   "source": [
    "## type 14\n",
    "save_path = type_14_path[:-20]\n",
    "\n",
    "print('%s 갯수 : %d\\n' % (type_14, len(pw_data)))\n",
    "print(pw_data[:5])\n",
    "\n",
    "file_name_src = pw_data.columns[0]\n",
    "file_name_tgt = pw_data.columns[1]\n",
    "print('%s -> %s'%(file_name_src, file_name_tgt))\n",
    "\n",
    "# src, tgt 전체 데이터 저장(csv)\n",
    "path1 = os.path.join(save_path, 'pw_all.pickle')\n",
    "pw_data.to_pickle(path1)  \n",
    "\n",
    "################################################################ split\n",
    "df_train, df_tmp = train_test_split(pw_data, test_size=0.2)\n",
    "df_valid, df_test = train_test_split(df_tmp, test_size=0.5)\n",
    "\n",
    "# train, valid, test 저장(txt)\n",
    "path = os.path.join(save_path, 'pw_train.pickle')\n",
    "df_train.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_valid.pickle')\n",
    "df_valid.to_pickle(path)\n",
    "\n",
    "path = os.path.join(save_path, 'pw_test.pickle')\n",
    "df_test.to_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
